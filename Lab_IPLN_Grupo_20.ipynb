{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Introducción al Procesamiento de Lenguaje Natural 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupo 20 - Mateo Nogueira - 4.830.584-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Importación del corpus\n",
    "Utilizamos la librería pandas para importar y analizar el corpus de los tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "# Entrenamiento\n",
    "corpus = pandas.read_csv(\"corpus_humor_training.csv\",encoding='utf-8')\n",
    "# Validación\n",
    "corpus2 = pandas.read_csv(\"corpus_humor_testing.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Análisis del corpus\n",
    "Realizamos un breve análisis del contenido del corpus antes del preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento \n",
      "\n",
      "El total de tweets es de: 12106\n",
      "\n",
      "La cantidad de votos de 1 estrella es de: 2960\n",
      "La cantidad de votos de 2 estrella es de: 2421\n",
      "La cantidad de votos de 3 estrella es de: 3274\n",
      "La cantidad de votos de 4 estrella es de: 2541\n",
      "La cantidad de votos de 5 estrella es de: 1616\n",
      "La cantidad de votos negativos es de: 14131\n",
      "\n",
      "El total de votos es de: 26943\n",
      "\n",
      "Evaluación\n",
      "\n",
      "El total de tweets es de: 3027\n",
      "\n",
      "La cantidad de votos de 1 estrella es de: 738\n",
      "La cantidad de votos de 2 estrella es de: 663\n",
      "La cantidad de votos de 3 estrella es de: 856\n",
      "La cantidad de votos de 4 estrella es de: 696\n",
      "La cantidad de votos de 5 estrella es de: 454\n",
      "La cantidad de votos negativos es de: 3457\n",
      "\n",
      "El total de votos es de: 6864\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenamiento \\n\")\n",
    "\n",
    "cantTweets = len(corpus.index)\n",
    "\n",
    "cantVotos1 = corpus['1'].sum()\n",
    "cantVotos2 = corpus['2'].sum()\n",
    "cantVotos3 = corpus['3'].sum()\n",
    "cantVotos4 = corpus['4'].sum()\n",
    "cantVotos5 = corpus['5'].sum()\n",
    "cantVotosN = corpus['n'].sum()\n",
    "\n",
    "print (\"El total de tweets es de: \" + str(cantTweets)+\"\\n\")\n",
    "print (\"La cantidad de votos de 1 estrella es de: \"+str(cantVotos1))\n",
    "print (\"La cantidad de votos de 2 estrella es de: \"+str(cantVotos2))\n",
    "print (\"La cantidad de votos de 3 estrella es de: \"+str(cantVotos3))\n",
    "print (\"La cantidad de votos de 4 estrella es de: \"+str(cantVotos4))\n",
    "print (\"La cantidad de votos de 5 estrella es de: \"+str(cantVotos5))\n",
    "print (\"La cantidad de votos negativos es de: \"+str(cantVotosN)+\"\\n\")\n",
    "\n",
    "print (\"El total de votos es de: \"+str(cantVotos1+cantVotos2+cantVotos3+cantVotos4+cantVotos5+cantVotosN))\n",
    "\n",
    "# Evaluacion\n",
    "\n",
    "print(\"\\nEvaluación\\n\")\n",
    "\n",
    "cantTweets = len(corpus2.index)\n",
    "\n",
    "cantVotos1 = corpus2['1'].sum()\n",
    "cantVotos2 = corpus2['2'].sum()\n",
    "cantVotos3 = corpus2['3'].sum()\n",
    "cantVotos4 = corpus2['4'].sum()\n",
    "cantVotos5 = corpus2['5'].sum()\n",
    "cantVotosN = corpus2['n'].sum()\n",
    "\n",
    "print (\"El total de tweets es de: \" + str(cantTweets)+\"\\n\")\n",
    "print (\"La cantidad de votos de 1 estrella es de: \"+str(cantVotos1))\n",
    "print (\"La cantidad de votos de 2 estrella es de: \"+str(cantVotos2))\n",
    "print (\"La cantidad de votos de 3 estrella es de: \"+str(cantVotos3))\n",
    "print (\"La cantidad de votos de 4 estrella es de: \"+str(cantVotos4))\n",
    "print (\"La cantidad de votos de 5 estrella es de: \"+str(cantVotos5))\n",
    "print (\"La cantidad de votos negativos es de: \"+str(cantVotosN)+\"\\n\")\n",
    "\n",
    "print (\"El total de votos es de: \"+str(cantVotos1+cantVotos2+cantVotos3+cantVotos4+cantVotos5+cantVotosN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el conjunto de entrenamiento tenemos 12106 tweets y 26943 votos lo que nos da un promedio de 2,2 votos por tweet mientras que en el de evaluación tenemos 3027 tweets y 3457 votos dando un promedio de 1,1 votos por tweet.\n",
    "\n",
    "Ambos suman 15133 tweets por lo que se realizó una separacion entre entrenamiento y evaluación de 75%/25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIpico: Ir por la calle. Saludar a alguien. Que no te devuelva el saludo. Pensar... A ÉSTE YA NO LE SALUDO MÁS.\n",
      "\n",
      "Decir que es una larga historia para no contarla.\n",
      "\n",
      "#CancionesParaRumbear Sexy And Know It - LMFAO\n",
      "\n",
      "—Doctor, doctor, no puedo recordar nada. —¿Desde cuándo tiene este problema? —¿Cuál problema?\n",
      "\n",
      "La gente lo llama día de San Valentín. Yo lo llamo jueves.\n",
      "\n",
      "RT @CiseProgresa: El entorno y los consumidores se han transformado completamente y los que estén preparados para adaptarse liderarán el nu…\n",
      "\n",
      "Por esas abuelas que no aceptan un \"no quiero más\" como respuesta.\n",
      "\n",
      "Típico: Ir a la casa de tu amigo y que su madre te tome como ejemplo de buen comportamiento, cuando eres peor que él.\n",
      "\n",
      "Si te dice fea, es porque eres guapa, nadie le dice fea a una fea.\n",
      "\n",
      "Mirar el celular cuando no quieres saludar a alguien.\n",
      "\n",
      "Matar mentalmente a quien no soportas.\n",
      "\n",
      "Todos tenemos una canción que nos hace llorar, sonreír y recordar. ¿Cuál es la tuya?\n",
      "\n",
      "—Tienes clase, hijo. —Gracias, mamá, soy un caballero. —Tienes clase mañana. Ya duérmete, pendejo.\n",
      "\n",
      "Yo + ? = Ni se te ocurra hablarme.\n",
      "\n",
      "Mi novio tiene sexo con muchas, para cuando este conmigo ser el mejor. Lo sé, me ama!.\n",
      "\n",
      "- ¿Y la dieta? -Me la comí :(\n",
      "\n",
      "A QUE NO SABES LEER EN INGLES... Lee esto rápido: (Teen, Go, Pick, A, Son, In, My, Cool, Low) Excelente! Te felicito. #fb\n",
      "\n",
      "¿FELICIDAD?... Felicidad es darle la vuelta a la almohada y seguir durmiendo del lado frío.\n",
      "\n",
      "¿Cuál es la enfermedad del 1 + 2? El ESTRESS #fb\n",
      "\n",
      "-Papá, hoy me habló una chica - ¿Si? ¿Y qué te dijo? -La base de datos de virus ha sido actualizada.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus['text'][140:160]:\n",
    "    print(text + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estos 20 tweets impresos se puede observar como hay distintos tipos de humor. \n",
    "\n",
    "Vemos como chistes que utilizan diálogos gracias a los ' - ', algunos tweets que contienen una pregunta y su respuesta, y simples enunciados. En estos 20 no ocurre, pero mirando por arriba todos los tweets detectamos que había tweets informaban de noticias o anunciaban ventas entre otros.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "\"COMPRA AQUI=&gt;http://t.co/AmFcnsGlM7      \n",
    "\n",
    "OFERTAS=&gt;http://t.co/9aHOTbR5kP  \"\n",
    "\n",
    "Hay tweets que utilizan otros idiomas para intentar ser humorísticos, por ejemplo el sigiuente tweet contiene letras del alfabeto árabe para decir que los médicos escriben cosas ilegibles. No sabemos que podría suceder al pasarle a un analizador como freeling este tipo de tweets.\n",
    "\n",
    "\"— ¿Entonces qué tengo doctor? — خيف الخاص خي — Gracias!\"\n",
    "\n",
    "\n",
    "Encontramos también un tweet que intenta ser gracioso jugando con la pronunciación. En este caso el clasificador debería ser capaz de detectar que 'digite' puede ser la pronunciación de 'dijiste' para alguna persona que no pronuncie la 's'. Esto claramente supone un problema debido a que sería necesario considerar como se pronuncia el tweet más que solo como esta escrito.\n",
    "\n",
    "\"Un indito en un cajero lee: \"Digite la clave\"... Y dice: ¡No, yo no li diji la clave a naiden!  #fb\"\n",
    "\n",
    "\n",
    "Finalmente encontramos hashtags y etiquetas de otras cuentas que consideramos que no aportan nada a la clasificación.\n",
    "\n",
    "Hay que tener en cuenta que hay 12106 tweets y esto fue solamente un breve análisis viendo algunos pocos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Preprocesamiento\n",
    "Como se solicita en la consigna eliminamos los tweets con menos de tres votos y además creamos la columna humoristico con contenido si/no en base a si es humoristico o no. (\"Humorístico si la mitad o más de los anotadores lo calificaron con una o más estrellas y no humorístico en caso contrario.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Elimino los tweets con menos de tres votos\n",
    "corpus = corpus.drop(corpus[corpus['1'] +corpus['2']+corpus['3']+corpus['4']+corpus['5']+corpus['n'] < 3].index)\n",
    "corpus2 = corpus2.drop(corpus2[corpus2['1'] +corpus2['2']+corpus2['3']+corpus2['4']+corpus2['5']+corpus2['n'] < 3].index)\n",
    "\n",
    "# Creo la columna humoristico para clasificar a un tweet si cumple la condición o no.\n",
    "corpus['humoristico'] = np.where(corpus['1']+corpus['2']+corpus['3']+corpus['4']+corpus['5'] >= (corpus['n']+corpus['1']+corpus['2']+corpus['3']+corpus['4']+corpus['5'])/2,'si','no')\n",
    "corpus2['humoristico'] = np.where(corpus2['1']+corpus2['2']+corpus2['3']+corpus2['4']+corpus2['5'] >= (corpus2['n']+corpus2['1']+corpus2['2']+corpus2['3']+corpus2['4']+corpus2['5'])/2,'si','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento \n",
      "\n",
      "El total de tweets es de: 3438\n",
      "\n",
      "Cantidad de tweets humoristicos: 1835\n",
      "Cantidad de tweets no humoristicos: 1603\n",
      "\n",
      "Evaluación\n",
      "\n",
      "El total de tweets es de: 877\n",
      "\n",
      "Cantidad de tweets humoristicos: 476\n",
      "Cantidad de tweets no humoristicos: 401\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenamiento \\n\")\n",
    "\n",
    "cantTweets = len(corpus.index)\n",
    "print (\"El total de tweets es de: \" + str(cantTweets)+\"\\n\")\n",
    "\n",
    "si = 0\n",
    "no = 0\n",
    "\n",
    "for index, row in corpus.iterrows():\n",
    "    if row['humoristico'] == 'si':\n",
    "        si = si + 1\n",
    "    else:\n",
    "        no = no + 1\n",
    "\n",
    "print (\"Cantidad de tweets humoristicos: \"+ str(si))\n",
    "print (\"Cantidad de tweets no humoristicos: \"+str(no))\n",
    "\n",
    "print(\"\\nEvaluación\\n\")\n",
    "\n",
    "cantTweets = len(corpus2.index)\n",
    "print (\"El total de tweets es de: \" + str(cantTweets)+\"\\n\")\n",
    "\n",
    "si = 0\n",
    "no = 0\n",
    "\n",
    "for index, row in corpus2.iterrows():\n",
    "    if row['humoristico'] == 'si':\n",
    "        si = si + 1\n",
    "    else:\n",
    "        no = no + 1\n",
    "\n",
    "print (\"Cantidad de tweets humoristicos: \"+ str(si))\n",
    "print (\"Cantidad de tweets no humoristicos: \"+str(no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la cantidad de tweets bajo bastante, en el caso del conjunto de entrenamiento tenemos más de 3 veces menos tweets y en el de entrenamiento sucede algo similar.\n",
    "\n",
    "Tenemos para ambos casos mas tweets humorísticos y la cantidad de tweets de evaluación es de aproximadamente (en tamaño) el 25% de la cantidad de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Clasificador Parte 1\n",
    "Para realizar el clasificador utilizaremos la librería scikit-learn. La misma es una librería de aprendizaje automático para python de código abierto que implementa una gran cantidad de algoritmos. En particular implementa los algoritmos de Naïve Bayes y SVM que podrán sernos de utilidad a la hora de clasificar los tweets. \n",
    "\n",
    "Para empezar importamos algunas funciones y definimos otras que nos van a ser de utilidad para procesar y evaluar el rendimiento de la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import sem\n",
    "\n",
    "# Dividimos el corpus en entrenamiento y evaluación. Con una proporción de 80%/20% \n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus.text, corpus.humoristico, test_size=0.20, random_state=1)\n",
    "\n",
    "# La siguiente función se encarga de entrenar un clasificador y \n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print (\"Accuracy en el conjunto de entrenamiento:\")\n",
    "    print (clf.score(X_train, y_train))\n",
    "    print (\"Accuracy en el conjunto de prueba:\")\n",
    "    print (clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print (\"Reporte:\")\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "    print (\"Matriz de confusión:\")\n",
    "    print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar un clasificador necesitamos extraer los features primero. scikit-learn provee varias clases para esta tarea. En particular posee un modulo específico para extracción de features en texto. Utilizaremos la clase CountVectorizer. La misma convierte los textos a una matriz númerica.\n",
    "\n",
    "CountVectorizer funciona siguiendo un estilo bag of words. (preprocesa, tokeniza, cuenta y normaliza). También es posible específicar stop words.\n",
    "\n",
    "Destacamos que todo esto lo hace automáticamente sin intervención de nosotros. Sin embargo vamos a modificar algunas de estas funciones para tokenizar utilizando Freeling y borrar los hashtags de los tweets.\n",
    "\n",
    "Vamos a utilizar la clase Pipeline de scikit-learn que nos permite extraer los features y pasarselos a un clasificador en una misma línea, lo cual reduce un poco la cantidad de líneas utilizadas mejorando la legibilidad.\n",
    "\n",
    "Vamos a probar utilizar un clasificador Naïve Bayes uno Support Vector Machines y uno de entropía máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importamos Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Importamos los clasificadores SVM, NB y entropía máxima\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización con FreeLing\n",
    "Lo primero que vamos a realizar es tokenizar nosotros los tweets utilizando FreeLing. Esta es una herramienta para análisis de lenguaje y esta hecha en C++. Trae una API para python.\n",
    "\n",
    "FreeLing lo bajamos e instalamos desde su página de GitHub\n",
    "(https://github.com/TALP-UPC/FreeLing/releases)\n",
    "Para poder ejecutar lo siguiente es necesario tenerlo instalado y configurar las variables FREELINGDIR y DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de freeling.\n",
    "\n",
    "import freeling\n",
    "\n",
    "\n",
    "FREELINGDIR = \"/usr/local\";\n",
    "\n",
    "DATA = FREELINGDIR+\"/share/freeling/\";\n",
    "LANG=\"es\";\n",
    "\n",
    "freeling.util_init_locale(\"default\");\n",
    "\n",
    "# create language analyzer\n",
    "la=freeling.lang_ident(DATA+\"common/lang_ident/ident.dat\");\n",
    "\n",
    "# create options set for maco analyzer. Default values are Ok, except for data files.\n",
    "op= freeling.maco_options(\"es\");\n",
    "op.set_data_files( \"\", \n",
    "                   DATA + \"common/punct.dat\",\n",
    "                   DATA + LANG + \"/dicc.src\",\n",
    "                   DATA + LANG + \"/afixos.dat\",\n",
    "                   \"\",\n",
    "                   DATA + LANG + \"/locucions.dat\", \n",
    "                   DATA + LANG + \"/np.dat\",\n",
    "                   DATA + LANG + \"/quantities.dat\",\n",
    "                   DATA + LANG + \"/probabilitats.dat\");\n",
    "\n",
    "# create analyzers\n",
    "tk=freeling.tokenizer(DATA+LANG+\"/tokenizer.dat\");\n",
    "sp=freeling.splitter(DATA+LANG+\"/splitter.dat\");\n",
    "sid=sp.open_session();\n",
    "mf=freeling.maco(op);\n",
    "\n",
    "# activate mmorpho odules to be used in next call\n",
    "mf.set_active_options(False, True, True, True,  # select which among created \n",
    "                      True, True, False, True,  # submodules are to be used. \n",
    "                      True, True, True, True ); # default: all created submodules are used\n",
    "\n",
    "# create tagger, sense anotator, and parsers\n",
    "tg=freeling.hmm_tagger(DATA+LANG+\"/tagger.dat\",True,2);\n",
    "sen=freeling.senses(DATA+LANG+\"/senses.dat\");\n",
    "parser= freeling.chart_parser(DATA+LANG+\"/chunker/grammar-chunk.dat\");\n",
    "dep=freeling.dep_txala(DATA+LANG+\"/dep_txala/dependences.dat\", parser.get_start_symbol());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La siguiente función se encarga de recibir un string y realizar su procesamiento\n",
    "\n",
    "def freelTok(lin):\n",
    "\n",
    "    l = tk.tokenize(lin);\n",
    "    ls = sp.split(sid,l,True);\n",
    "\n",
    "    ls = mf.analyze(ls);\n",
    "    ls = tg.analyze(ls);\n",
    "    ls = sen.analyze(ls);\n",
    "    ls = parser.analyze(ls);\n",
    "    ls = dep.analyze(ls);\n",
    "    return ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es necesario cerrar la sesión iniciada por freeling\n",
    "#sp.close_session(sid);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de vectorizador\n",
    "\n",
    "Creamos un vectorizador que hereda de CountVectorizer en el que modificamos la función de tokenizar y preprocesamiento, de forma de eliminar los hashtags, simbolos de puntación y considerar stop words.\n",
    "\n",
    "Vamos a crear nuestra propia función de tokenizar y preprocesar para pasar como parámetro a CountVectorizer.\n",
    "\n",
    "Primero se van a eliminar hashtags, etiquetas de otras cuentas y símbolos de puntuación. Después se va a tokenizar usando freeling y eliminar stopwords según la lista obtenida de la libería NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Ejecuto la siguiente línea para bajar el corpus de stopwords de NLTK.\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords1 = stopwords.words('spanish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def AnalizadorTweet(tweet):\n",
    "    \n",
    "    # Borro hashtags\n",
    "    tweet = re.sub(r'\\b#.+','',tweet)\n",
    "    \n",
    "    # Borro etiquetas\n",
    "    tweet = re.sub(r'\\b@.+','',tweet)\n",
    "    \n",
    "    retornar = []\n",
    "    postFreeling = freelTok(tweet)\n",
    "    for s in postFreeling:\n",
    "        ws=s.get_words()\n",
    "        for w in ws:\n",
    "            # Elimino stopwords\n",
    "            if w.get_lemma().lower() not in stopwords1:\n",
    "                # Elimino símbolos de puntuacion\n",
    "                if w.get_lemma() not in string.punctuation:\n",
    "                    retornar.append(w.get_lemma())\n",
    "                    retornar.append(w.get_tag())\n",
    "    #print(retornar)\n",
    "    return retornar\n",
    "\n",
    "\n",
    "vectorizador = CountVectorizer(analyzer=AnalizadorTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrenar vamos a normalizar utilizando TF-IDF (term frequency - inverse document frequency). Este es un peso estadístico para evaluar que tan importante es una palabra para un documento en un corpus.\n",
    "\n",
    "El valor TF-IDF (importancia) de un token aumenta proporcionalmente a la cantidad de apariciones que un token tiene en un tweet pero se compensa por la frecuencia de aparición en el corpus.\n",
    "\n",
    "Esto permite tener en cuenta que en general hay palabras más frecuentes que otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn trae una clase para esto\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "# Creamos los clasificadores:\n",
    "\n",
    "# Naïve Bayes\n",
    "nb= Pipeline([('vect', vectorizador),('tfid',tfidf),('clf', MultinomialNB()),])\n",
    "\n",
    "# SVM\n",
    "svm= Pipeline([('vect', vectorizador),('tfid',tfidf),('clf', SGDClassifier(max_iter=1000)),])\n",
    "\n",
    "# Entropía Máxima\n",
    "maxent= Pipeline([('vect', vectorizador),('tfid',tfidf),('clf', LogisticRegressionCV()),])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es necesario seleccionar el modelo ajustando los parámetros específicos de cada clasificador. En el teórico vimos dos posibles opciones separar el corpus de entrenamiento en dos corpus (con una proporción 80/20 %) para entrenar sobre el primero, evaluar sobre el segundo y ajustar o utilizar cross-validation donde el corpus se divide en k partes, se entrena sobre k-1, evalua en la restante, se repite para cada parte y se toma la media.\n",
    "\n",
    "ScikitLearn posee la clase GridSearchCV que nos permite indicar valores para ciertos parámetros y luego se entrena como un clasificador normal, durante el entrenamiento utiliza cross validation para seleccionar de los parámetros dados los mejores.\n",
    "\n",
    "En general, para el vectorizador y el tfidf vamos a probar con los siguientes parámetros:\n",
    "\n",
    "'binary' del vectorizador en True o en False, este parámetro según la documentación de scikitlearn da mejores resultados en True para eventos binarios como el que nos enfrentamos (si / no)\n",
    "\n",
    "'ngram_range' del vectorizador: Es una tupla (min_n, max_n) que indica el mínimo n y el máximo n de los n-gramas a utilizar. Vamos a probar con unigramas, bigramas, unigramas + bigramas, unigramas + bigramas + trigramas, bigramas + trigramas.\n",
    "\n",
    "'use_idf' del tfidf: Booleano que permite la reasignación de pesos idf.\n",
    "\n",
    "'sublinear_tf' del tfidf: Aplica escalamiento sublineal (reemplazar la frecuencia de un término por 1+log(frecuencia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de naïve bayes vamos a probar solamente ajustar los parámetros 'fit_prior' y 'alpha'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_nb = {'vect__binary': (True, False), \n",
    "                 'vect__ngram_range': [(1, 1), (2, 2), (1, 2), (1, 3), (2, 3)],\n",
    "                 'tfid__use_idf': (True, False),\n",
    "                 'tfid__sublinear_tf': (True, False),\n",
    "                 'clf__alpha': (1e-2, 1e-3, 1, 1e-1),\n",
    "                 'clf__fit_prior': (True, False) }\n",
    "\n",
    "# n_jobs indica que utilice todos los cores del CPU\n",
    "grid_nb = GridSearchCV(nb, parametros_nb, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.885689354276\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.743443557583\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.71      0.74      0.73       401\n",
      "         si       0.77      0.75      0.76       476\n",
      "\n",
      "avg / total       0.74      0.74      0.74       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[297 104]\n",
      " [121 355]]\n"
     ]
    }
   ],
   "source": [
    "print('Naïve Bayes \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_nb,corpus['text'],corpus2['text'],corpus['humoristico'],corpus2['humoristico'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de SVM vamos a probar ajustar 'alpha', parámetro que multiplica el término de normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_svm = {'vect__binary': (True, False), \n",
    "                 'vect__ngram_range': [(1, 1), (2, 2), (1, 2), (1, 3), (2, 3)],\n",
    "                 'tfid__use_idf': (True, False),\n",
    "                 'tfid__sublinear_tf': (True, False),\n",
    "                 'clf__alpha': (1e-2, 1e-4, 1e-1) }\n",
    "\n",
    "# n_jobs indica que utilice todos los cores del CPU\n",
    "\n",
    "grid_svm = GridSearchCV(svm, parametros_svm, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.88801628854\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.745724059293\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.73      0.71      0.72       401\n",
      "         si       0.76      0.78      0.77       476\n",
      "\n",
      "avg / total       0.75      0.75      0.75       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[283 118]\n",
      " [105 371]]\n"
     ]
    }
   ],
   "source": [
    "print('SVM \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_svm,corpus['text'],corpus2['text'],corpus['humoristico'],corpus2['humoristico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_maxent = {'vect__binary': (True, False), \n",
    "                     'vect__ngram_range': [(1, 1), (2, 2), (1, 2), (1, 3), (2, 3)],\n",
    "                     'tfid__use_idf': (True, False),\n",
    "                     'tfid__sublinear_tf': (True, False),\n",
    "                     'clf__refit': (True, False),\n",
    "                     'clf__fit_intercept': (True, False) }\n",
    "\n",
    "# n_jobs indica que utilice todos los cores del CPU\n",
    "grid_maxent = GridSearchCV(maxent, parametros_maxent, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máxima Entropía \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.837696335079\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.762827822121\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.74      0.75      0.74       401\n",
      "         si       0.79      0.77      0.78       476\n",
      "\n",
      "avg / total       0.76      0.76      0.76       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[301 100]\n",
      " [108 368]]\n"
     ]
    }
   ],
   "source": [
    "print('Máxima Entropía \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_maxent,corpus['text'],corpus2['text'],corpus['humoristico'],corpus2['humoristico'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que naive bayes y SVM tuvieron, en promedio, un accuracy similar tanto en el conjunto de prueba como en el de entrenamiento de aproximadamente 74%. Ambos alcanzan casi un 88% en el conjunto de entrenamiento lo que muestra que los clasificadores estan teniendo un sobreajuste sobre en el conjunto de entrenamiento debido a la diferencia con el desempeño en el de prueba.\n",
    "\n",
    "El clasificador de entropía máxima no solo obtuvo un desempeño en el conjunto de prueba si no que además la diferencia con el conjunto de entrenamiento es mucho menor que en los anteriores, lo que indica menos sobreajuste. En este caso la matriz de confusión nos muestra que se equivoco la misma cantidad de tweets.\n",
    "\n",
    "Los tres tuvieron una mejor precisión cuando se trato de tweets humorísticos, por lo que estan un poco desvíados hacía el 'si'. En el caso de Naïve Bayes, la diferencia de precisión entre 'si' y 'no' alcanzo un 6%, en SVM un 3% y en entropía máxima un 5%. En cuanto a recall se observan porcentajes similares a los de la precisión por lo que la medida f1, siendo una medida armónica entre precisión y recall también es similar a la precisión y el recall. \n",
    "\n",
    "\n",
    "En base a lo anterior consideramos que el mejor clasificador fue el de entropía máxima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Clasificador Parte 2\n",
    "Para realizar este clasificador necesitamos ademas estimar la mediana de los tweets humorísticos. Para esto creamos una nueva columna 'mediana' de la misma manera que antes solo que ahora en ves de 'si' va a ir la mediana de los votos y 0 va a significar no humorístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statistics import median\n",
    "from math import ceil\n",
    "\n",
    "mediana = []\n",
    "\n",
    "for index, row in corpus.iterrows():\n",
    "    Calcmediana = []\n",
    "    \n",
    "    for iter in range (0, int(row['1'])):\n",
    "        Calcmediana.append(1)\n",
    "    for iter in range (0, int(row['2'])):\n",
    "        Calcmediana.append(2)\n",
    "    for iter in range (0, int(row['3'])):\n",
    "        Calcmediana.append(3)\n",
    "    for iter in range (0, int(row['4'])):\n",
    "        Calcmediana.append(4)\n",
    "    for iter in range (0, int(row['5'])):\n",
    "        Calcmediana.append(5)\n",
    "    for iter in range (0, int(row['n'])):\n",
    "        Calcmediana.append(0)\n",
    "        \n",
    "    mediana.append(ceil(median(Calcmediana)))\n",
    "    \n",
    "mediana2 = []\n",
    "\n",
    "for index, row in corpus2.iterrows():\n",
    "    Calcmediana2 = []\n",
    "    \n",
    "    for iter in range (0, int(row['1'])):\n",
    "        Calcmediana2.append(1)\n",
    "    for iter in range (0, int(row['2'])):\n",
    "        Calcmediana2.append(2)\n",
    "    for iter in range (0, int(row['3'])):\n",
    "        Calcmediana2.append(3)\n",
    "    for iter in range (0, int(row['4'])):\n",
    "        Calcmediana2.append(4)\n",
    "    for iter in range (0, int(row['5'])):\n",
    "        Calcmediana2.append(5)\n",
    "    for iter in range (0, int(row['n'])):\n",
    "        Calcmediana2.append(0)\n",
    "        \n",
    "    mediana2.append(ceil(median(Calcmediana2)))\n",
    "\n",
    "\n",
    "corpus2['mediana'] = mediana2    \n",
    "corpus['mediana'] = mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelvo a entrenar los clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.749854566608\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.476624857469\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.94      0.69       401\n",
      "          1       0.27      0.10      0.14       125\n",
      "          2       0.23      0.13      0.17       122\n",
      "          3       0.18      0.11      0.14       139\n",
      "          4       0.00      0.00      0.00        77\n",
      "          5       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.35      0.48      0.38       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[375   6  10   9   1   0]\n",
      " [ 87  12   9  17   0   0]\n",
      " [ 78   8  16  20   0   0]\n",
      " [ 95  11  18  15   0   0]\n",
      " [ 39   6  16  16   0   0]\n",
      " [  5   1   2   5   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateo/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Naïve Bayes \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_nb,corpus['text'],corpus2['text'],corpus['mediana'],corpus2['mediana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.524432809773\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.45724059293\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.93      0.65       401\n",
      "          1       0.28      0.07      0.11       125\n",
      "          2       0.19      0.04      0.07       122\n",
      "          3       0.22      0.09      0.13       139\n",
      "          4       0.06      0.01      0.02        77\n",
      "          5       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.34      0.46      0.35       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[373   6   8  10   3   1]\n",
      " [ 96   9   6  12   2   0]\n",
      " [ 91   5   5  15   4   2]\n",
      " [109   6   7  13   4   0]\n",
      " [ 62   5   1   8   1   0]\n",
      " [  8   1   0   2   2   0]]\n"
     ]
    }
   ],
   "source": [
    "print('SVM \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_svm,corpus['text'],corpus2['text'],corpus['mediana'],corpus2['mediana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropía Máxima \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.4845840605\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.467502850627\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.97      0.66       401\n",
      "          1       0.21      0.18      0.19       125\n",
      "          2       0.00      0.00      0.00       122\n",
      "          3       0.00      0.00      0.00       139\n",
      "          4       0.00      0.00      0.00        77\n",
      "          5       0.00      0.00      0.00        13\n",
      "\n",
      "avg / total       0.26      0.47      0.33       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[388  13   0   0   0   0]\n",
      " [103  22   0   0   0   0]\n",
      " [ 96  26   0   0   0   0]\n",
      " [115  24   0   0   0   0]\n",
      " [ 62  15   0   0   0   0]\n",
      " [  7   6   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateo/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Entropía Máxima \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_maxent,corpus['text'],corpus2['text'],corpus['mediana'],corpus2['mediana'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos resultados similares en el conjunto de evaluación para los tres clasificadores. No sucede lo mismo en el conjunto de entrenamiento donde en Naïve Bayes se observa un sobreajuste al corpus de entrenamiento debido a que hay una diferencia de casi 30% entre el accuracy en evaluación y entrenamiento.\n",
    "\n",
    "Mirando la precisión, vemos que el clasificador de entropía máxima fue el peor de todos, dado que no clasifico ningún tweet como de dos o más estrellas ni correctamente ni incorrectamente. La mejor precisión la tuvo el clasificador de SVM, que fue capaz de clasificar bien tweets con 4 estrellas, algo que los otros dos no pudieron.\n",
    "\n",
    "Hay un recall muy alto en 0 estrellas de 93%, 94% y 97% y considerando su precisión de 50%, 50% y 55% nos muestra que hay una tendencia a marcar un tweet como 0 estrellas.\n",
    "\n",
    "\n",
    "Decidimos por el motivo de poder detectar tweets de hasta 4 estrellas que el mejor clasificador en esta etapa es del SVM.\n",
    "\n",
    "Tenemos que observar también que se observan warnings de que hay etiquetas sin muestras predecidas, por lo que consideramos que esta clasificación no es muy fiable y deberia repetirse la prueba con un corpus más grande, con más ejemplos para todas las etiquetas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Clasificador Parte 3\n",
    "Para este clasificador vamos a utilizar la columna del corpus 'mediana' calculada en la parte anterior. En base a esta columna creamos una nueva 'humoristicoP3' que va a valer 'si' sí para esa fila la columna 'mediana' valia 1 o más y 'no' en caso de que 'mediana' tuviera valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "humoristicoP3 = []\n",
    "humoristicoP3_2 = []\n",
    "\n",
    "for index, row in corpus.iterrows():\n",
    "    if row['mediana'] > 0:\n",
    "        humoristicoP3.append('si')\n",
    "    else:\n",
    "        humoristicoP3.append('no')\n",
    "        \n",
    "for index, row in corpus2.iterrows():\n",
    "    if row['mediana'] > 0:\n",
    "        humoristicoP3_2.append('si')\n",
    "    else:\n",
    "        humoristicoP3_2.append('no')\n",
    "        \n",
    "\n",
    "corpus['humoristicoP3'] = humoristicoP3\n",
    "corpus2['humoristicoP3'] = humoristicoP3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.885689354276\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.743443557583\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.71      0.74      0.73       401\n",
      "         si       0.77      0.75      0.76       476\n",
      "\n",
      "avg / total       0.74      0.74      0.74       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[297 104]\n",
      " [121 355]]\n"
     ]
    }
   ],
   "source": [
    "print('Naïve Bayes \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_nb,corpus['text'],corpus2['text'],corpus['humoristicoP3'],corpus2['humoristicoP3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.888307155323\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.745724059293\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.73      0.71      0.72       401\n",
      "         si       0.76      0.78      0.77       476\n",
      "\n",
      "avg / total       0.75      0.75      0.75       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[283 118]\n",
      " [105 371]]\n"
     ]
    }
   ],
   "source": [
    "print('SVM \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_svm,corpus['text'],corpus2['text'],corpus['humoristicoP3'],corpus2['humoristicoP3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropía Máxima \n",
      "\n",
      "Accuracy en el conjunto de entrenamiento:\n",
      "0.837696335079\n",
      "Accuracy en el conjunto de prueba:\n",
      "0.762827822121\n",
      "Reporte:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.74      0.75      0.74       401\n",
      "         si       0.79      0.77      0.78       476\n",
      "\n",
      "avg / total       0.76      0.76      0.76       877\n",
      "\n",
      "Matriz de confusión:\n",
      "[[301 100]\n",
      " [108 368]]\n"
     ]
    }
   ],
   "source": [
    "print('Entropía Máxima \\n')\n",
    "# Entreno y evalúo performance\n",
    "train_and_evaluate(grid_maxent,corpus['text'],corpus2['text'],corpus['humoristicoP3'],corpus2['humoristicoP3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos resultados exactamente iguales a los del clasificador de la parte 1. Vamos a ver si hubo algún tweet que cambio de humorístico a no humorístico comparando ambos criterios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in corpus.iterrows():\n",
    "    if row['humoristico'] != row['humoristicoP3']:\n",
    "        print(row['text']+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La salida en blanco muestra que en este corpus ambos criterios son equivalentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Conclusiones\n",
    "\n",
    "De los resultados anteriores podemos concluir que el criterio utilizado para la parte 1 y  la parte 3 nos dan resultados equivalentes. Esto es, considerar un tweet como humorístico si la mitad o más de los anotadores lo calificaron con una o más estrellas, o, si la mediana de la cantidad de estrellas es mayor que 0 son equivalentes. Para un trabajo futuro se podría intentar encontrar un contraejemplo para mostrar si esto ocurre siempre o fue casualidad o en caso de no encontrarlo intentar demostrar matemáticamente que son equivalentes.\n",
    "\n",
    "Para la parte 2 obtuvimos resultados muy malos en comparación con las otras partes pero consideramos que es debido a que tenemos muchas etiquetas y pocas muestras para cada una por lo que es necesario obtener un corpus más grande con la suficiente cantidad de muestras clasificadas y repetir el experimento en un futuro.\n",
    "\n",
    "También es necesario tener en cuenta que el humor es subjetivo y lo que para una persona es humorístico para otra podría no serlo. Se podría ser un poco mas específico en este tema si se distinguiera por tipo de chiste que contiene el tweet o quienes son los anotadores (un ejemplo para esto sería distingiuir por franjas de edades)[1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://www.fing.edu.uy/inco/grupos/pln/prygrado/Informepghumor.pdf\n",
    "\n",
    "[2] http://scikit-learn.org/stable/documentation.html\n",
    "\n",
    "[3] http://nlp.lsi.upc.edu/freeling/\n",
    "\n",
    "[4] http://www.nltk.org/\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
